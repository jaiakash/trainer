{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c49a6d5",
   "metadata": {},
   "source": [
    "# Fine-tune Llama-3.2-1B-Instruct with Alpaca Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b15eff",
   "metadata": {},
   "source": [
    "This example demonstrates how to fine-tune Llama-3.2-1B-Instruct model with the Alpaca Dataset using TorchTune `BuiltinTrainer` from Kubeflow Trainer SDK.\n",
    "\n",
    "This notebooks walks you through the prerequisites of using TorchTune `BuiltinTrainer` from Kubeflow Trainer SDK, and how to submit TrainJob to bootstrap the fine-tuning workflow.\n",
    "\n",
    "Llama-3.2-1B-Instruct: https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct\n",
    "\n",
    "Alpaca Dataset: https://huggingface.co/datasets/tatsu-lab/alpaca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a60eb",
   "metadata": {},
   "source": [
    "## Install the Kubeflow SDK\n",
    "\n",
    "You need to install the Kubeflow SDK to interact with Kubeflow Trainer APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ec515",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/jaiakash/sdk.git@backend-public"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7211fbf9",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### Install Official Training Runtimes\n",
    "\n",
    "You need to make sure that you've installed the Kubeflow Trainer Controller Manager and Kubeflow Training Runtimes mentioned in the [installation guide](https://www.kubeflow.org/docs/components/trainer/operator-guides/installation/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e4fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available Kubeflow Training Runtimes.\n",
    "from kubeflow.trainer import *\n",
    "from kubernetes import client as k8s_client\n",
    "import os\n",
    "\n",
    "client = TrainerClient()\n",
    "for runtime in client.list_runtimes():\n",
    "    print(runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb5f256",
   "metadata": {},
   "source": [
    "### Create PVCs for Models and Datasets\n",
    "\n",
    "Currently, we do not support automatically orchestrate the volume claim in (Cluster)TrainingRuntime.\n",
    "\n",
    "So, we need to manually create PVCs for each models we want to fine-tune. Please note that **the PVC name must be equal to the ClusterTrainingRuntime name**. In this example, it's `torchtune-llama3.2-1b`.\n",
    "\n",
    "REF: https://github.com/kubeflow/trainer/issues/2630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11cc7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PersistentVolumeClaim for the TorchTune Llama 3.2 1B model.\n",
    "client.backend.core_api.create_namespaced_persistent_volume_claim(\n",
    "  namespace=\"default\",\n",
    "  body=k8s_client.V1PersistentVolumeClaim(\n",
    "    api_version=\"v1\",\n",
    "    kind=\"PersistentVolumeClaim\",\n",
    "    metadata=k8s_client.V1ObjectMeta(name=\"torchtune-llama3.2-1b\"),\n",
    "    spec=k8s_client.V1PersistentVolumeClaimSpec(\n",
    "      access_modes=[\"ReadWriteOnce\"],\n",
    "      resources=k8s_client.V1ResourceRequirements(\n",
    "        requests={\"storage\": \"200Gi\"}\n",
    "      ),\n",
    "    ),\n",
    "  ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67490f66",
   "metadata": {},
   "source": [
    "## Bootstrap LLM Fine-tuning Workflow\n",
    "\n",
    "Kubeflow TrainJob will train the model in the referenced (Cluster)TrainingRuntime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641fae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = client.train(\n",
    "    runtime=client.get_runtime(name=\"torchtune-llama3.2-1b\"),\n",
    "    initializer=Initializer(\n",
    "        dataset=HuggingFaceDatasetInitializer(\n",
    "            storage_uri=\"hf://tatsu-lab/alpaca/data\"\n",
    "        ),\n",
    "        model=HuggingFaceModelInitializer(\n",
    "            storage_uri=\"hf://meta-llama/Llama-3.2-1B-Instruct\",\n",
    "            access_token=os.environ[\"HF_TOKEN\"] # Replace with your Hugging Face token,\n",
    "        )\n",
    "    ),\n",
    "    trainer=BuiltinTrainer(\n",
    "        config=TorchTuneConfig(\n",
    "            dataset_preprocess_config=TorchTuneInstructDataset(\n",
    "                source=DataFormat.PARQUET, split=\"train[:1000]\"\n",
    "            ),\n",
    "            resources_per_node={\n",
    "                \"memory\": \"200G\",\n",
    "                \"gpu\": 1,\n",
    "            },\n",
    "            \n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a82b76",
   "metadata": {},
   "source": [
    "## Watch the TrainJob Logs\n",
    "\n",
    "We can use the `get_job_logs()` API to get the TrainJob logs.\n",
    "\n",
    "### Dataset Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.trainer.constants import constants\n",
    "\n",
    "log_dict = client.get_job_logs(job_name, follow=False, step=constants.DATASET_INITIALIZER)\n",
    "print(log_dict[constants.DATASET_INITIALIZER])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f970c03",
   "metadata": {},
   "source": [
    "### Model Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict = client.get_job_logs(job_name, follow=False, step=constants.MODEL_INITIALIZER)\n",
    "print(log_dict[constants.MODEL_INITIALIZER])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67775ea",
   "metadata": {},
   "source": [
    "### Trainer Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae672d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict = client.get_job_logs(job_name, follow=False)\n",
    "print(log_dict[f\"{constants.NODE}-0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ebbb6",
   "metadata": {},
   "source": [
    "# Get the Fine-tuned Model\n",
    "\n",
    "After Trainer node completes the fine-tuning task, the fine-tuned model will be stored into the `/workspace/output` directory, which can be shared across Pods through PVC mounting. You can find it in another Pod's `/<mountDir>/output` directory if you mount the PVC under `/<mountDir>`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
